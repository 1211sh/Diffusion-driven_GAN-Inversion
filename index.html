<!DOCTYPE html>
<html>
<head>
	<title>Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation</title>
	<meta property="og:image" content="./resources/fig_overview_5-1.png"/>
	<meta property="og:title" content="Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation" />
	<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
	<script type="text/javascript">google.load("jquery", "1.3.2");</script>
	<style type="text/css">
		body {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
			font-weight:300;
			font-size:18px;
			margin-left: auto;
			margin-right: auto;
			width: 1100px;
		}
		
		h1 {
			font-size:32px;
			font-weight:300;
		}
		
		.disclaimerbox {
			background-color: #eee;		
			border: 1px solid #eeeeee;
			border-radius: 10px ;
			-moz-border-radius: 10px ;
			-webkit-border-radius: 10px ;
			padding: 20px;
		}

		video.header-vid {
			height: 140px;
			border: 1px solid black;
			border-radius: 10px ;
			-moz-border-radius: 10px ;
			-webkit-border-radius: 10px ;
		}
		
		img.header-img {
			height: 140px;
			border: 1px solid black;
			border-radius: 10px ;
			-moz-border-radius: 10px ;
			-webkit-border-radius: 10px ;
		}
		
		img.rounded {
			border: 1px solid #eeeeee;
			border-radius: 10px ;
			-moz-border-radius: 10px ;
			-webkit-border-radius: 10px ;
		}
		
		a:link,a:visited
		{
			color: #1367a7;
			text-decoration: none;
		}
		a:hover {
			color: #208799;
		}
		
		td.dl-link {
			height: 160px;
			text-align: center;
			font-size: 22px;
		}
		
		.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
			0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
			5px 5px 0 0px #fff, /* The second layer */
			5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
			10px 10px 0 0px #fff, /* The third layer */
			10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
			15px 15px 0 0px #fff, /* The fourth layer */
			15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
			20px 20px 0 0px #fff, /* The fifth layer */
			20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
			25px 25px 0 0px #fff, /* The fifth layer */
			25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
			margin-left: 10px;
			margin-right: 45px;
		}

		.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
			0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

			margin-left: 10px;
			margin-right: 45px;
		}


		.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
			box-shadow:
			0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
			5px 5px 0 0px #fff, /* The second layer */
			5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
			10px 10px 0 0px #fff, /* The third layer */
			10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
			margin-top: 5px;
			margin-left: 10px;
			margin-right: 30px;
			margin-bottom: 5px;
		}
		
		.vert-cent {
			position: relative;
			top: 50%;
			transform: translateY(-50%);
		}
		
		hr
		{
			border: 0;
			height: 1px;
			background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
		}
	</style>
</head>
<body>
	<br>
	<center>
		<span style="font-size:36px">Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation<br> </span>
		<table align=center width=1100px>
			<table align=center width=1100px>
				<tr>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.com/citations?hl=en&user=EyHyvWEAAAAJ">Jihyun Kim<sup>1,2</sup></a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.co.kr/citations?user=wQVWb98AAAAJ&hl=ko">Changjae Oh<sup>3</sup></a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.co.kr/citations?user=52vpqpcAAAAJ&hl=ko">Hoseok Do<sup>1</sup></a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.com/citations?user=oDplwx8AAAAJ&hl=ko&oi=sra">Soohyun Kim<sup>1</sup></a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.com/citations?user=zEtk0QsAAAAJ&hl=en">Kwanghoon Sohn<sup>*,2</sup></a></span>
						</center>
					</td>
				</tr>
			</table>
						
			<table align=center width=1000px>
				<tr>
					<td align=center width=130px>
						<center>
							<span style="font-size:20px">AI Lab, CTO Division, LG Electronics<sup>1</sup></a></span>
						</center>
					</td>
	
					<td align=center width=140px>
						<center>
							<span style="font-size:20px">Yonsei University<sup>2</sup></a></span>
						</center>
					</td>
				</tr>

				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">Queen Mary University London<sup>3</sup></a></span>
						</center>
					</td>

					<td align=center width=180px>
						<center>
							<span style="font-size:20px">Corresponding Author<sup>*</sup></a></span>
						</center>
					</td>
				</tr>
			</table>
						
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://arxiv.org/abs/2405.04356'>[Paper]</a></span>
						</center>
					</td>
					
				</tr>
			</table>
		</table>
	</center>
	<br>

	<center><h1>CVPR 2024 Video</h1></center>
	<table align=center width=850px>
		<tr>
			<td align=center width=850px>
				<center>
					<video width="800px" height="600px" controls>
						<source src="./resources/cvpr2024_video.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					
				</td>
			</tr>
		</center>
	</table>

	<br>
	<hr>
	
	<center>
		<table align=center width=750px>
			<tr>
				<td width=400px>
					<center>
						<img class="round" style="width:600px" src="./resources/fig1.PNG"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				We present a new multi-modal face image generation method that converts a text prompt and a visual input, such as a semantic mask or scribble map, into a photo-realistic face image. 
				To do this, we combine the strengths of GAN and diffusion models by employing the multi-modal features in the diffusion model into the latent space of the pre-trained GANs. 
				We present a simple mapping network and a style modulation network to link two models and convert meaningful representations in feature maps and attention maps into latent codes. 
				With GAN inversion, the estimated latent codes can be used to generate 2D or 3D-aware facial images. 
				We further present a multi-step training strategy that reflects textual and structural representations into the generated image. 
				By leveraging our proposed networks, realistic 2D, 3D, and stylized face images are produced, which align well with inputs. 
				We validate our method by using pre-trained 2D and 3D GANs, and our results outperform existing methods. 
			</td>
		</tr>
	</table>
	<br>
	<hr>

	<center><h1> Overview of our method  </h1></center>
	
	<table align=center width=600px>
		<tr>
			<td align=center width=600px>
				<center>
					<td><img class="round" style="width:800px" src="./resources/fig_overview_5-1.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					We use the mapping network, a diffusion-based encoder, the middle and decoder blocks of a denoising U-Net, that extracts the semantic features, intermediate features, and cross-attention maps.
				</td>
			</tr>
		</center>
	</table>

	<br>
	<hr>

	<center><h1> Quantitative results </h1></center>

	<table align=center width=600px>
		<tr>
			<td align=center width=600px>
				<center>
					<td><img class="round" style="width:800px" src="./resources/cvpr2024_tab1.PNG"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					 Quantitative results of multi-modal face image generation on CelebAMask-HQ with annotated text prompts.
				</td>
			</tr>
		</center>
	</table>
	<br>
	<hr>

	<center><h1> Visual examples </h1></center>
	
	<table align=center width=210px>
		<tr>
			<td align=center width=210px>
				<center>
					<td><img class="round" style="width:800px" src="./resources/fig_result_editing_2d_3-1.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Visual examples of the 2D face image generation using a text prompt and a semantic mask.
				</td>
			</tr>
		</center>
	</table>

	<br>
	<table align=center width=210px>
		<tr>
			<td align=center width=210px>
				<center>
					<td><img class="round" style="width:800px" src="./resources/fig6.PNG"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Visual examples of the 3D-aware face image generation using a text and a semantic mask. We show the images generated with inputs and arbitrary viewpoints.
				</td>
			</tr>
		</center>
	</table>
	<br>

	<table align=center width=210px>
		<tr>
			<td align=center width=210px>
				<center>
					<td><img class="round" style="width:500px" src="./resources/fig7.PNG"/></td>
				</center>
			</td>
		</tr>
	</table>


	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Visual examples of multi-view face image generation using text prompts and scribble maps. Using (1-4) the text prompts and their corresponding (a) scribble maps, we compare the results of (b) ControlNet with (c) multi-view images generated by ours.
				</td>
			</tr>
		</center>
	</table>

	<br>

	<table align=center width=210px>
		<tr>
			<td align=center width=210px>
				<center>
					<td><img class="round" style="width:600px" src="./resources/supp_fig3.PNG"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					The results of 3D face style transfer using semantic masks and style text prompts.
			</tr>
		</center>
	</table>

	<br>

	<table align=center width=210px>
		<tr>
			<td align=center width=210px>
				<center>
					<td><img class="round" style="width:800px" src="./resources/supp_fig4.PNG"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Results for verifying the semantic consistency. We keep the text prompts but change the components of visual inputs in Figure 5 of the main paper, such as hair, glasses, and eyes.
			</tr>
		</center>
	</table>

	<br>
	<hr>

	<center><h1>CVPR 2024 Poster</h1></center>
	<table align=center width=850px>
		<tr>
			<td align=center width=850px>
				<center>
					<td><img class="round" style="width:800px" src="./resources/cvpr_poster_png.png"/></td>
					<!-- <iframe src="./resources/cvpr_poster_png.png" width="800px" height="600px"></iframe> -->
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					CVPR 2024 Poster
				</td>
			</tr>
		</center>
	</table>
	<br>
	<hr>

	

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

	<br>
</body>
</html>
